{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import differential_entropy,kurtosis\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Majew(gamma, alpha, kappa1, beta, Lambda, sigmav, length = 1000, nb = 1 ):\n",
    "    #nb : nb de simulations\n",
    "    # length : taille de la serie temporelle\n",
    "    Epsilon=np.random.normal(0, sigmav**2, (length,nb))\n",
    "    v=np.zeros((length,nb))\n",
    "    m=np.zeros((length,nb))\n",
    "    \n",
    "    # We initialize the different functions we will need\n",
    "    \n",
    "    p=np.zeros((length,nb))\n",
    "    r=np.zeros((length,nb))\n",
    "    p[0] = 200\n",
    "    # We initialize the price\n",
    "    \n",
    "    for t in range(1,length-1):\n",
    "        \n",
    "        v[t] = (1-Lambda)*v[t-1] + Lambda*p[t]\n",
    "        \n",
    "        m[t] = (1-alpha)*m[t-1] + alpha*(p[t]-p[t-1])\n",
    "        \n",
    "        p[t+1] = p[t] + kappa1*(v[t]-p[t]) + beta*np.tanh(gamma*m[t]) + Epsilon[t+1]\n",
    "        \n",
    "        r[t+1] = p[t+1] - p[t]\n",
    "    \n",
    "    return p,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(r, cov=False):\n",
    "    means = np.mean(r, axis=0)\n",
    "    std_dev = np.std(r, axis=0)\n",
    "    entropy = differential_entropy(r, axis = 0)\n",
    "    kurtosiss = kurtosis(r, axis=0)\n",
    "    \n",
    "    q1 = np.percentile(r, 25, axis=0)\n",
    "    q2 = np.percentile(r, 50, axis=0)\n",
    "    q3 = np.percentile(r, 75, axis=0)\n",
    "    \n",
    "    \n",
    "    if cov:\n",
    "        mf = np.vstack([means, std_dev, entropy, kurtosiss, q1, q2, q3])\n",
    "        W = np.cov(mf)\n",
    "        \n",
    "        return np.array([np.mean(means), np.mean(std_dev), np.mean(entropy), np.mean(kurtosiss), np.mean(q1), np.mean(q2), np.mean(q3)]), W\n",
    "    \n",
    "    return np.array([np.mean(means), np.mean(std_dev), np.mean(entropy), np.mean(kurtosiss), np.mean(q1), np.mean(q2), np.mean(q3)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.06813223e-01,  1.24019575e+00, -5.20500067e+00,  7.00129506e+01,\n",
       "       -3.71993475e-04, -6.56648783e-05,  1.77820311e-04])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, r_thild = Majew(0.015,1/7,0.015,36.7,0.2,0.018)\n",
    "c_thilde = compute_statistics(r_thild)\n",
    "c_thilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(ksi):\n",
    "    _, r = Majew(*ksi, nb = 100)\n",
    "    cabm, V = compute_statistics(r, cov=True)\n",
    "    dc = c_thilde - cabm\n",
    "    W = np.linalg.inv(V)\n",
    "    D = dc.T @ W @ dc\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'maxiter': 10000,     # Maximum number of iterations        # Precision goal for the function value         # Precision goal for the gradient\n",
    "    'disp': True          # Display convergence messages\n",
    "}\n",
    "init = (0.02,1/9,0.01,32.7,0.3,0.02)\n",
    "res = minimize(cost, init, method='Nelder-Mead', options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.93293D+08    |proj g|=  2.69091D+16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    1    f=  5.90732D+08    |proj g|=  3.45466D+16\n",
      "L-BFGS-B Result:\n",
      "At iterate    2    f=  8.07778D+08    |proj g|=  1.82615D+16\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6      2     28      1     0     0   1.826D+16   8.078D+08\n",
      "  F =   807777751.00563478     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "\n",
      "  message: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 807777751.0056348\n",
      "        x: [ 2.000e-02  1.111e-01  1.000e-02  3.270e+01  3.000e-01\n",
      "             2.000e-02]\n",
      "      nit: 2\n",
      "      jac: [-1.226e+16 -1.826e+16 -1.507e+16 -1.546e+16 -1.519e+16\n",
      "             1.009e+16]\n",
      "     nfev: 182\n",
      "     njev: 26\n",
      " hess_inv: <6x6 LbfgsInvHessProduct with dtype=float64>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    }
   ],
   "source": [
    "# Define the options for L-BFGS-B\n",
    "options_lbfgsb = {\n",
    "    'maxiter': 1000,\n",
    "    'ftol': 1e-9,\n",
    "    'gtol': 1e-9,\n",
    "    'disp': True\n",
    "}\n",
    "init_lbfgsb = (0.02,1/9,0.01,32.7,0.3,0.02)\n",
    "# Perform the optimization using 'L-BFGS-B' method\n",
    "res_lbfgsb = minimize(cost, init_lbfgsb, method='L-BFGS-B', options=options_lbfgsb)\n",
    "print(\"L-BFGS-B Result:\")\n",
    "print(res_lbfgsb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1365/1640456040.py:21: RuntimeWarning: overflow encountered in multiply\n",
      "  p[t+1] = p[t] + kappa1*(v[t]-p[t]) + beta*np.tanh(gamma*m[t]) + Epsilon[t+1]\n",
      "/tmp/ipykernel_1365/1640456040.py:17: RuntimeWarning: overflow encountered in multiply\n",
      "  v[t] = (1-Lambda)*v[t-1] + Lambda*p[t]\n",
      "/tmp/ipykernel_1365/1640456040.py:17: RuntimeWarning: invalid value encountered in add\n",
      "  v[t] = (1-Lambda)*v[t-1] + Lambda*p[t]\n",
      "/tmp/ipykernel_1365/1640456040.py:19: RuntimeWarning: overflow encountered in multiply\n",
      "  m[t] = (1-alpha)*m[t-1] + alpha*(p[t]-p[t-1])\n",
      "/tmp/ipykernel_1365/1640456040.py:19: RuntimeWarning: invalid value encountered in add\n",
      "  m[t] = (1-alpha)*m[t-1] + alpha*(p[t]-p[t-1])\n",
      "/tmp/ipykernel_1365/1640456040.py:21: RuntimeWarning: invalid value encountered in subtract\n",
      "  p[t+1] = p[t] + kappa1*(v[t]-p[t]) + beta*np.tanh(gamma*m[t]) + Epsilon[t+1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration limit reached    (Exit mode 9)\n",
      "            Current function value: nan\n",
      "            Iterations: 1000\n",
      "            Function evaluations: 17988\n",
      "            Gradient evaluations: 1000\n",
      "SLSQP Result:\n",
      " message: Iteration limit reached\n",
      " success: False\n",
      "  status: 9\n",
      "     fun: nan\n",
      "       x: [       nan        nan        nan        nan        nan\n",
      "                  nan]\n",
      "     nit: 1000\n",
      "     jac: [       nan        nan        nan        nan        nan\n",
      "                  nan]\n",
      "    nfev: 17988\n",
      "    njev: 1000\n"
     ]
    }
   ],
   "source": [
    "# Initial guess\n",
    "init_slsqp = (0.02,1/9,0.01,32.7,0.3,0.02)\n",
    "\n",
    "# Define the options for SLSQP\n",
    "options_slsqp = {\n",
    "    'maxiter': 1000,\n",
    "    'ftol': 1e-9,\n",
    "    'disp': True\n",
    "}\n",
    "\n",
    "# Perform the optimization using 'SLSQP' method\n",
    "res_slsqp = minimize(cost, init_slsqp, method='SLSQP', options=options_slsqp)\n",
    "print(\"SLSQP Result:\")\n",
    "print(res_slsqp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1365/3342169377.py:12: OptimizeWarning: Unknown solver options: maxiter\n",
      "  res_tnc = minimize(cost, init_tnc, method='TNC', options=options_tnc)\n",
      "  NIT   NF   F                       GTG\n",
      "    0    1  9.071449716598027E+08   7.21147732E+32\n",
      "tnc: fscale = 1.89521e-18\n",
      "    1   11  7.015524316081628E+08   1.24501358E+33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TNC Result:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tnc: |xn-xn-1] = 1.45215e-08 -> convergence\n",
      "    2   15  5.797449716158283E+08   1.62143251E+33\n",
      "tnc: Converged (|x_n-x_(n-1)| ~= 0)\n"
     ]
    }
   ],
   "source": [
    "# Initial guess\n",
    "init_tnc = (0.02,1/9,0.01,32.7,0.3,0.02)\n",
    "\n",
    "# Define the options for TNC\n",
    "options_tnc = {\n",
    "    'maxiter': 1000,\n",
    "    'disp': True,\n",
    "    'gtol': 1e-9\n",
    "}\n",
    "\n",
    "# Perform the optimization using 'TNC' method\n",
    "res_tnc = minimize(cost, init_tnc, method='TNC', options=options_tnc)\n",
    "print(\"TNC Result:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "808251360.0913874\n"
     ]
    }
   ],
   "source": [
    "print(cost(res_tnc.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: 630663267.921971\n",
      "         Iterations: 1\n",
      "         Function evaluations: 89\n",
      "         Gradient evaluations: 11\n",
      "BFGS Result:\n",
      "  message: Desired error not necessarily achieved due to precision loss.\n",
      "  success: False\n",
      "   status: 2\n",
      "      fun: 630663267.9219714\n",
      "        x: [ 2.000e-02  1.111e-01  1.000e-02  3.270e+01  3.000e-01\n",
      "             2.000e-02]\n",
      "      nit: 1\n",
      "      jac: [ 1.354e+16  9.438e+15  7.303e+15  8.084e+15  6.096e+15\n",
      "            -5.925e+15]\n",
      " hess_inv: [[ 5.276e-01 -3.342e-01 ... -3.032e-01  2.370e-01]\n",
      "            [-3.342e-01  7.697e-01 ... -1.006e-01  1.296e-01]\n",
      "            ...\n",
      "            [-3.032e-01 -1.006e-01 ...  2.908e+00 -5.507e-01]\n",
      "            [ 2.370e-01  1.296e-01 ... -5.507e-01  1.116e+00]]\n",
      "     nfev: 89\n",
      "     njev: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.12/site-packages/scipy/optimize/_minimize.py:708: OptimizeWarning: Desired error not necessarily achieved due to precision loss.\n",
      "  res = _minimize_bfgs(fun, x0, args, jac, callback, **options)\n"
     ]
    }
   ],
   "source": [
    "# Initial guess\n",
    "init_bfgs = (0.02,1/9,0.01,32.7,0.3,0.02)\n",
    "\n",
    "# Define the options for BFGS\n",
    "options_bfgs = {\n",
    "    'maxiter': 10000,\n",
    "    'gtol': 1e-9,\n",
    "    'disp': True\n",
    "}\n",
    "\n",
    "# Perform the optimization using 'BFGS' method\n",
    "res_bfgs = minimize(cost, init_bfgs, method='BFGS', options=options_bfgs)\n",
    "print(\"BFGS Result:\")\n",
    "print(res_bfgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Majew2(gamma, alpha, kappa1, kappa3, beta, Lambda, sigmav):\n",
    "    \n",
    "    Epsilon=np.random.normal(0, sigmav**2, (length,nb))\n",
    "    v=np.zeros((length,nb))\n",
    "    m=np.zeros((length,nb))\n",
    "    \n",
    "    # We initialize the different functions we will need\n",
    "    \n",
    "    p=np.zeros((length,nb))\n",
    "    r=np.zeros((length,nb))\n",
    "    \n",
    "    # We initialize the price\n",
    "    \n",
    "    for t in range(1,length-1):\n",
    "        \n",
    "        v[t] = (1-Lambda)*v[t-1] + Lambda*p[t]\n",
    "        \n",
    "        m[t] = (1-alpha)*m[t-1] + alpha*(p[t]-p[t-1])\n",
    "        \n",
    "        p[t+1] = p[t] + kappa1*(v[t]-p[t]) + kappa3*(v[t]-p[t]) + beta*np.tanh(gamma*m[t]) + Epsilon[t+1]\n",
    "        \n",
    "        r[t+1] = p[t+1] - p[t]\n",
    "    \n",
    "    return p,r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
